---
title: "Tensor Flo Ridas: A Journey in Machine Learning"
output: 
  html_document:
    toc: TRUE
    toc_depth: 1
    toc_float: TRUE
---

```{r load_libraries, include = FALSE}
# load required packages
library(tidyverse)
library(tidymodels)
library(here)
library(rio)
library(workflows)
library(vip)

theme_set(theme_minimal())
```

***

# Linear Model 

To get a general understanding of how our predictor variables fit our data, we begin by fitting a basic linear regression model to our data akin to `stats::lm`. 

```{r import_data, include = FALSE}
# read in data set
data <- read_csv("data/train.csv",
                 col_types = cols(.default = col_guess(), calc_admn_cd = col_character()))  %>% 
    select(-classification)

# read in free/reduced lunch data and student counts
frl <- import(here("data", "lunch.csv"),
              setclass = "tbl_df")  %>% 
  janitor::clean_names()  %>% 
  filter(st == "OR")  %>%
  select(ncessch, lunch_program, student_count)  %>% 
  mutate(student_count = replace_na(student_count, 0))  %>% 
  pivot_wider(names_from  = lunch_program,
              values_from = student_count)  %>% 
  janitor::clean_names()  %>% 
  mutate(ncessch = as.double(ncessch))

stu_counts <- import("https://github.com/datalorax/ach-gap-variability/raw/master/data/achievement-gaps-geocoded.csv",
                     setclass = "tbl_df")  %>% 
  filter(state == "OR" & year == 1718)  %>% 
  count(ncessch, wt = n)  %>% 
  mutate(ncessch = as.double(ncessch))

frl <- left_join(frl, stu_counts)

rm(stu_counts)

frl <- frl %>% 
  mutate(free_lunch_prop    = free_lunch_qualified / n,
         reduced_lunch_prop = reduced_price_lunch_qualified / n)  %>% 
  select(ncessch, ends_with("prop"))

# read in staff data
staff <- import(here("data", "staff.csv"), setclass = "tbl_df")  %>% 
  janitor::clean_names()  %>% 
  filter(st == "OR")  %>%
  mutate(ncessch = as.double(ncessch)) %>%
  select(ncessch, teachers)

# read in school characteristics data
school_chars <- import(here("data", "school_characteristics.csv"), setclass = "tbl_df")  %>% 
  janitor::clean_names()  %>% 
  filter(st == "OR")  %>%
  mutate(ncessch = as.double(ncessch)) %>%
  select(ncessch, titlei_status, nslp_status, virtual)

# read in ethnicity data
eth <- import(file     = here::here("data", "fallmembershipreport_20192020.xlsx"), 
            sheet    = "School (19-20)",
            setclass = "tibble") %>%
  janitor::clean_names() %>%
  select(attnd_schl_inst_id = attending_school_id,
         sch_name           = school_name,
         matches("percent"))

names(eth) <- gsub("x2019_20_percent", "p", names(eth)) 

# combine our data with frl, staff, school characteristics, and ethnicities
data <- data %>%
    left_join(frl) %>%
    left_join(staff) %>%
    left_join(school_chars) %>%
    left_join(eth)

# remove unneeded dataframes
rm(frl, staff, school_chars, eth)
```

```{r cv_split, include = FALSE}
set.seed(3000)

# data %<>%
#   select(-matches("lat|lon|native|multi|black"))

# data <- data %>%
#   sample_frac(prop = .01)

data_split <- initial_split(data)

data_train <- training(data_split)

data_test  <- testing(data_split)

data_train_cv <- vfold_cv(data_train)
```

# Recipe 

We will use the recipe we have created from our 

```{r rec_1}
recipe_1 <- recipe(score ~ ., data_train) %>%  
    step_mutate(tst_dt = lubridate::mdy_hms(tst_dt)) %>%
    update_role(contains("id"), ncessch, sch_name, new_role = "id vars") %>%
    step_novel(all_nominal()) %>%
    step_unknown(all_nominal()) %>%
    step_zv(all_predictors()) %>%
    step_normalize(all_numeric(), -all_outcomes(), -has_role("id vars")) %>%
    step_BoxCox(all_numeric(), -all_outcomes(), -has_role("id vars")) %>%
    step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars")) %>%
    step_dummy(all_nominal(), -has_role("id vars"), one_hot = TRUE) %>%
    step_zv(all_predictors())
```

## Examine recipe 

```{r}

recipe_1

temp <- prep(recipe_1) 

tidy(temp)

#novel
tidy(temp, 2) %>% 
  print(n = Inf)

#unknown
tidy(temp, 3) %>% 
  print(n = Inf)

#nzv
tidy(temp, 4) %>% 
  print(n = Inf)

```

# Assemble Model 

```{r}

#create model 
lin_mod <- linear_reg() %>% 
  set_engine("lm")  %>% 
  set_mode("regression")

#create workflow
lin_workflow <- workflow() %>% 
  add_recipe(recipe_1) %>% 
  add_model(lin_mod)

#run model 
start_rf <- Sys.time()

lin_fit <- fit_resamples(
  lin_workflow,
  data_train_cv,
  metrics = yardstick::metric_set(rmse), 
  control = control_resamples(verbose = TRUE, 
                              save_pred = TRUE))
end_rf <- Sys.time()
(lin_time <- end_rf - start_rf)
```


## Collect Metrics 

```{r}
# see all RMSE
lin_fit %>% 
  collect_metrics(summarize = FALSE)

# see average RMSE 
lin_fit %>%
  collect_metrics(summarize = TRUE)
```

# Make Prediction

We will now make predictions on our left out dataset from our initial split. 

```{r}
#run the model on the withheld test set from the initial split 
start_rf <- Sys.time()

mod_lin_final <- last_fit(
lin_workflow, 
split = data_split)

end_rf <- Sys.time()
(lin_final_time <- end_rf - start_rf)
```


## Collect Metrics 
```{r}
mod_lin_final %>% 
  collect_metrics()
```

## Plot 
```{r}
mod_lin_final %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(num_features = 20) +
  labs(y = "Variable Importance", 
       title = "Variable Importance Plot for Linear Model") +
  theme(plot.title.position = "plot")
```


```{r, eval = FALSE, include = FALSE}
mod_lin_final %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(num_features = 20) +
  geom_bar(data = test2, aes(color = "test$fit$coefficients" > 0))


test <- mod_lin_final %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit()


test %>% unlist()


test2 <- as.data.frame(test$fit$coefficients) %>% top_n(20)

str(test2)


test2 <- as.table(test$fit$coefficients) %>% top_n(20)

 geom_point(aes(color = workplaces > 0), 
                 size = 2) +
      scale_color_brewer(palette = "Set2")
```

***

```{r, echo = FALSE}
today <- Sys.Date() 
```

<center>
*Last updated: `r format(today, format="%B %d %Y")`.*
</center>