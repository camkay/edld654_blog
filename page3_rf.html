<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Tensor Flo Ridas: A Journey in ML</title>

<script src="site_libs/header-attrs-2.5/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="custom.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">EDLD654</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="page1_data.html">
    <span class="fa fa-database"></span>
     
    The Data
  </a>
</li>
<li>
  <a href="page2_linear.html">
    <span class="fa fa-chart-line"></span>
     
    Linear Model
  </a>
</li>
<li>
  <a href="page3_rf.html">
    <span class="fa fa-tree"></span>
     
    Random Forest
  </a>
</li>
<li>
  <a href="page4_xgboost.html">
    <span class="fa fa-rocket"></span>
     
    Boosted Tree
  </a>
</li>
<li>
  <a href="page5_comparison.html">
    <span class="fa fa-balance-scale"></span>
     
    Model Comparisons
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/camkay/edld654_blog">
    <span class="fa fa-github"></span>
     
    GitHub
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Tensor Flo Ridas: A Journey in ML</h1>

</div>


<hr />
<div id="fitting-an-untuned-random-forest-model" class="section level1">
<h1>Fitting an untuned random forest model</h1>
<p>On this page, we provide an overview of how to fit and tune a random forest model. But, before we get into the fitting and tuning, it is important to describe what exactly a random forest model is and, before we do that, we need to describe what decision trees and bagging are.</p>
<p>An intuitive way to think of a decision tree is as a flow chart. Essentially, a decision tree predicts some outcome (whether it is continuous or categorical) by making a number of yes/no decisions on the predictors. For example, in predicting how much coffee a person drinks, the model might predict greater amounts if the person is over 18 (i.e., yes to over 18) than if they are under 18 (i.e., not to over 18) and if they are from Oregon than from other states. In doing so, it also captures interactions between the variables, such that the prediction for a 27-year-old Oregonian could be different from a 17-year old Oregonian and a 27-year-old Washingtonian.</p>
<p>The problem with a decision tree is that it can easily overfit to a given dataset. To address this issue, we can use bootstrap aggregation (i.e., bagging), which makes multiple decision trees based on a bootstrap resamples of the training data. In doing so, we are essentially creating a number of models that are more biased than the single decision tree would be. However, when we average those trees together, we reduce much of that bias and also end up with a model that has less overall variance.</p>
<p>Random forests further attempt to reduce this variance by making the trees built upon each of the resamples more dissimilar. It does this by randomly sampling some number of predictors for each tree (rather than including the same predictors in each tree). This reduces the likelihood that the same predictors will always be found higher up in the trees (e.g., at the roote node) because, in certain trees, those predictors won’t exist.</p>
<div id="creating-the-model" class="section level2">
<h2>Creating the model</h2>
<p>To fit a random forest model, we start by creating a specification of the model. To do this, we can use the <code>random_forest()</code> function from <code>{parsnip}</code>. Since we are predicting a continuous variable (i.e., <code>score</code>) we will want to set the mode (using <code>set_mode()</code>) to <code>"regression"</code>. We will also want to set the engine (using <code>set_engine()</code>). Here, we will be using the engine <code>"ranger"</code> because it is more efficient than <code>randomForest</code>. We also set <code>num.threads</code> to the number of cores on our computer. By providing this information, <code>ranger</code> is able to parallelize the process, speeding up the creating of the models. Setting <code>importance = "permutation"</code> means, when identifying the most important variables, the model will use permutation. Namely, predictors will be considered more importance if shuffling their values results in worse prediction error. We also set <code>verbose = TRUE</code> so that R tells us what step in the process we are at. Finally, we set argumetns using <code>set_args()</code>. In this case, we only se one argument, which was setting <code>trees</code> to <code>500</code>. This means that our random forest model will create 500 decision trees. Although this is less than the number of trees recommended by Max and Johnson (2013), we chose this value to improve computational efficiency and to minimize potential memory issues during tuning (i.e., exhausting vector memory in R).</p>
<pre class="r"><code>model_rf &lt;- rand_forest() %&gt;% 
  set_mode(&quot;regression&quot;) %&gt;% 
  set_engine(engine      = &quot;ranger&quot;,
             num.threads = parallel::detectCores(),
             importance  = &quot;permutation&quot;,
             verbose     = TRUE) %&gt;% 
  set_args(trees = 500)</code></pre>
</div>
<div id="creating-the-workflow" class="section level2">
<h2>Creating the workflow</h2>
<p>Once we have created the model, we can combine it with the recipe (see The Data (LINK HERE)) using <code>workflow()</code> from the <code>{workflows}</code> package. This allows us to only pass a single object (e.g., <code>workflow</code>) to fit our model instead of passing multiple objects (e.g., <code>recipe_1</code> <em>and</em> <code>model_rf</code>).</p>
<pre class="r"><code># create workflow object
workflow_rf &lt;- workflow() %&gt;% 
  add_recipe(recipe_1) %&gt;% 
  add_model(model_rf)</code></pre>
</div>
<div id="fitting-the-model" class="section level2">
<h2>Fitting the model</h2>
<p>Now all that is left is to fit our model using <code>fit_resamples</code>. Here we used <code>metrics = yardstick::metric_set(rmse, rsq)</code> to request calculation of the average <em>Root Mean Square Error</em> (RMSE) and <span class="math inline">\(R^2\)</span> for the model. We also used the arguments <code>tic()</code> and <code>toc()</code> from the aptly named <code>{tictoc}</code> package to measure how long it took the model to run.</p>
<pre class="r"><code># start timer
tictoc::tic()

# fit model
fit_rf &lt;- fit_resamples(
  object    = workflow_rf,
  resamples = data_train_cv,
  metrics   = yardstick::metric_set(rmse, rsq),
  control   = control_resamples(verbose   = TRUE,
                                save_pred = TRUE,
                                extract   = function(x) extract_model(x)))

# end timer
time1 &lt;- tictoc::toc()</code></pre>
<pre><code>## 169.693 sec elapsed</code></pre>
</div>
<div id="checking-model-metrics" class="section level2">
<h2>Checking model metrics</h2>
<p>Whew! It only took 169.693 seconds to run.</p>
<p>Now we can check how it fit using the <code>collect_metrics()</code> function.</p>
<pre class="r"><code>collect_metrics(fit_rf) # 86.2</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[".metric"],"name":[1],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[2],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[4],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"rmse","2":"standard","3":"86.1653101","4":"10","5":"0.580063517"},{"1":"rsq","2":"standard","3":"0.4381685","4":"10","5":"0.006731574"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We can see that it had an RMSE of 86.17 and a <span class="math inline">\(R^2\)</span> of 0.44. In other words, our predictors explained 43.82% of the variance in the scores.</p>
</div>
<div id="extracting-important-predictors" class="section level2">
<h2>Extracting important predictors</h2>
<p>We can also check the most important predictors in our trees using the <code>vip()</code> argument.</p>
<pre class="r"><code>pluck(fit_rf, &quot;.extracts&quot;, 1, &quot;.extracts&quot;, 1) %&gt;%
  vip(aesthetics = list(fill = &quot;cyan3&quot;), num_features = 20L) +
  labs(x = &quot;Predictor&quot;) + 
  theme_407()</code></pre>
<p><img src="page3_rf_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>As we can see, the students enrolment grade (<code>enrl_grade</code>) was one of the most importance predictors when it comes to predicting a students <code>score</code>. However, you might also note that the graph for the important predictors has quite a long tail. This is because we used a random forest model instead of simple bagging. As hinted at above, random forest models result in more variability of the most important predictors because only a subset of the predictors are included in each tree.</p>
</div>
</div>
<div id="fitting-a-tuned-random-forest-model" class="section level1">
<h1>Fitting a tuned random forest model</h1>
<p>As with the <a href="page2_linear.html">linear model</a>, we can also tune our model. With random forest models, there are three hyperparameters. The first is the number of <code>trees</code>, which we set to <code>500</code> in the previous model. However, with random forest models, people just have to ensure that there are enough trees (there is not the issue of too many trees). As a result, people commonly only tune the other two hyperparameters. The first of these is the minimum node side (<code>min_n</code>), which controls how deep a tree will grow. A larger value will result in shallower trees, and a smaller value will result in deeper trees. The deeper a tree, the more likely it is to have high variance, and the shallower a tree, the more likely it is to have high bias.</p>
<p>The second of these hyperparameters is <code>mtry</code>, which controls the number of predictors to sample for each tree. More predictors being sampled increases the similarities between the trees. As a result, it would increase the variance of models.</p>
<p>To keep computation times down, here we are only going to provide an example of how to tune <code>min_n</code>, but the process is quite similar for tuning <code>mtry</code>. Below we added <code>min_n = tune()</code> to <code>set_args()</code> to tune the <code>min_n</code> hyperparameter.</p>
<div id="creating-the-model-1" class="section level2">
<h2>Creating the model</h2>
<pre class="r"><code>model_rf_tune &lt;- rand_forest() %&gt;% 
  set_mode(&quot;regression&quot;) %&gt;% 
  set_engine(engine      = &quot;ranger&quot;,
             num.threads = parallel::detectCores(),
             importance  = &quot;permutation&quot;,
             verbose     = TRUE) %&gt;% 
  set_args(trees = 500,
           min_n = tune())</code></pre>
</div>
<div id="updating-the-workflow-object" class="section level2">
<h2>Updating the workflow object</h2>
<p>Now that we have created this new model, we can updated our workflow using the <code>update_model</code> function from <code>{workflows}</code>.</p>
<pre class="r"><code>workflow_rf_tune &lt;- workflow_rf %&gt;%
  update_model(model_rf_tune)</code></pre>
</div>
<div id="creating-the-tuning-grid" class="section level2">
<h2>Creating the tuning grid</h2>
<p>We also, however, have to tell <code>{tidymodels}</code> what potential values to use for <code>min_n</code>. To do so, we can use the <code>grid_regular()</code> argument from <code>{dials}</code>. Below we requested that 5 values (<code>levels</code>) be tried for <code>min_n</code> between <code>1</code> and <code>10</code>.</p>
<pre class="r"><code># create grid
grid_rf &lt;- grid_regular(min_n(range = c(1, 10)), 
                        levels      = 5)</code></pre>
</div>
<div id="fitting-the-model-1" class="section level2">
<h2>Fitting the model</h2>
<p>Now we can fit our model as we did above. However, we will now want to use <code>tune_grid()</code> instead of <code>fit_resamples()</code> because we want to fit a separate model for each value of the grid specified above. We also used <code>object = workflow_rf_tune</code> to pass our new workflow to <code>tune_grid()</code>, and <code>grid = grid_rf</code> to pass our grid to <code>tune_grid()</code>.</p>
<pre class="r"><code># start timer
tictoc::tic()

# fit model
fit_rf_tune &lt;- tune_grid(
  object    = workflow_rf_tune,
  resamples = data_train_cv,
  grid      = grid_rf,
  metrics   = yardstick::metric_set(rmse, rsq),
  control   = control_resamples(verbose   = TRUE,
                                save_pred = TRUE,
                                extract   = function(x) extract_model(x)))

# end timer
time2 &lt;- tictoc::toc()</code></pre>
<pre><code>## 779.163 sec elapsed</code></pre>
</div>
<div id="checking-model-metrics-1" class="section level2">
<h2>Checking model metrics</h2>
<p>This time, it took 779.163 seconds to run, but it is not surprising it took longer, because we fit five times the models (because we provided 5 hyperparameter values to test).</p>
<p>Now we can check how it fit using the <code>show_best()</code> function. We are using <code>show_best()</code> instead of <code>collect_metrics()</code> because we want to see the hyperparameters that produced best fitting models (as determined by the models RMSE).</p>
<pre class="r"><code>show_best(fit_rf_tune, metric = &quot;rmse&quot;, n = 10) # 85.8</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["min_n"],"name":[1],"type":["int"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"10","2":"rmse","3":"standard","4":"85.76636","5":"10","6":"0.5799668","7":"Model5"},{"1":"7","2":"rmse","3":"standard","4":"85.98384","5":"10","6":"0.5916483","7":"Model4"},{"1":"5","2":"rmse","3":"standard","4":"86.20442","5":"10","6":"0.5866762","7":"Model3"},{"1":"3","2":"rmse","3":"standard","4":"86.39005","5":"10","6":"0.5752793","7":"Model2"},{"1":"1","2":"rmse","3":"standard","4":"86.58000","5":"10","6":"0.5888000","7":"Model1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We can see that the best fitting model samples 10.00 predictors for each tree and has an RMSE of 85.77, an improvement over our previous RMSE of 86.17.</p>
</div>
<div id="plotting-the-tuned-values" class="section level2">
<h2>Plotting the tuned values</h2>
<p>To visualize the trend, we can use <code>autoplot()</code> to show us how average fit varied across different values of <code>min_n</code>.</p>
<pre class="r"><code>fit_rf_tune %&gt;%
  autoplot() +
  geom_line(color = &quot;cyan3&quot;) +
  geom_point(color = &quot;cyan3&quot;) +
  theme_407()</code></pre>
<p><img src="page3_rf_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Ah! We see that RMSE decreased all the way up to <code>min_n</code> equals <code>10</code>. Would it reduced even more if we provided an even higher <code>min_n</code>?</p>
</div>
<div id="further-tuning" class="section level2">
<h2>Further tuning</h2>
<p>We can test this by trying out a different grid. Let’s try a new grid, with 10 potential <code>min_n</code> values between <code>10</code> to <code>30</code></p>
<pre class="r"><code># create grid
grid_rf_2 &lt;- grid_regular(min_n(range = c(10, 30)), 
                          levels      = 10)</code></pre>
<p>We then refit the model.</p>
<pre class="r"><code># start timer
tictoc::tic()

# fit model
fit_rf_tune_2 &lt;- tune_grid(
  object    = workflow_rf_tune,
  resamples = data_train_cv,
  grid      = grid_rf_2,
  metrics   = yardstick::metric_set(rmse, rsq),
  control   = control_resamples(verbose   = TRUE,
                                save_pred = TRUE,
                                extract   = function(x) extract_model(x)))

# end timer
time3 &lt;- tictoc::toc()</code></pre>
<pre><code>## 1258.372 sec elapsed</code></pre>
<p>The new model took 1258.372 seconds to fit. Again, it makes sense that it is longer, because we are now testing <code>10</code> hyperparameters instead of <code>5</code>.</p>
<p>We can then look at the metrics again…</p>
<pre class="r"><code>show_best(fit_rf_tune_2, metric = &quot;rmse&quot;, n = 10) # 85.3</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["min_n"],"name":[1],"type":["int"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"27","2":"rmse","3":"standard","4":"85.30140","5":"10","6":"0.6179977","7":"Model09"},{"1":"30","2":"rmse","3":"standard","4":"85.33087","5":"10","6":"0.6262129","7":"Model10"},{"1":"25","2":"rmse","3":"standard","4":"85.33128","5":"10","6":"0.6097008","7":"Model08"},{"1":"23","2":"rmse","3":"standard","4":"85.37347","5":"10","6":"0.6069483","7":"Model07"},{"1":"21","2":"rmse","3":"standard","4":"85.40271","5":"10","6":"0.6232605","7":"Model06"},{"1":"18","2":"rmse","3":"standard","4":"85.49974","5":"10","6":"0.6154056","7":"Model05"},{"1":"16","2":"rmse","3":"standard","4":"85.56783","5":"10","6":"0.6065154","7":"Model04"},{"1":"14","2":"rmse","3":"standard","4":"85.59051","5":"10","6":"0.5936204","7":"Model03"},{"1":"12","2":"rmse","3":"standard","4":"85.70580","5":"10","6":"0.5862275","7":"Model02"},{"1":"10","2":"rmse","3":"standard","4":"85.79425","5":"10","6":"0.5941898","7":"Model01"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>…and the plot showing RMSE by <code>min_n</code>.</p>
<pre class="r"><code>fit_rf_tune_2 %&gt;%
  autoplot() +
  geom_line(color = &quot;cyan3&quot;) +
  geom_point(color = &quot;cyan3&quot;) +
  theme_407()</code></pre>
<p><img src="page3_rf_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>It looks like the best <code>min_n</code> (of the values we tested) is 27.00 which resulted in an average model RMSE of 85.30. This is marginally better than our previous best RMSE of 85.77.</p>
</div>
</div>
<div id="finalizing-the-model" class="section level1">
<h1>Finalizing the model</h1>
<p>Now that if we have promising hyper parameters, we can fit our model on the left out testing data. To do so, we will first want to finalize the workflow (using <code>finalize_workflow()</code>) to use the most performant hyperparameters.</p>
<pre class="r"><code>workflow_rf_final &lt;- finalize_workflow(
  workflow_rf_tune,
  select_best(fit_rf_tune_2, metric = &quot;rmse&quot;)
)</code></pre>
<p>Then we fit our model on our initial split data (<code>data_split</code>) using <code>last_fit()</code>.</p>
<pre class="r"><code># start timer
tictoc::tic()

# produce final fit
fit_rf_final &lt;- last_fit(workflow_rf_final, split = data_split)

# end timer
time4 &lt;- tictoc::toc()</code></pre>
<pre><code>## 14.523 sec elapsed</code></pre>
<p>Unsurprisingly, it was much faster to fit the model, coming in at 1258.372 seconds, because we only were not testing multiple hyperparameters.</p>
<pre class="r"><code>collect_metrics(fit_rf_final) # 87.2</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[".metric"],"name":[1],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimate"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"rmse","2":"standard","3":"87.2479913"},{"1":"rsq","2":"standard","3":"0.4365835"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The RMSE for the assessment set was <!--87.25).--></p>
</div>
<div id="final-thoughts" class="section level1">
<h1>Final thoughts</h1>
<p>Although the final model on the assessment set had a greater RMSE (i.e., <!--87.25-->) than the last model fit on the analysis set (i.e., 85.30), but it is not drastically so. We can, therefore, likely conclude that the model has relatively low variance.</p>
<p>In terms of final thoughts about tuning the model, even when only using <code>500</code> <code>trees</code>, testing only <code>15</code> different values for the minimum node size (i.e., <code>min_n</code>), and using only <code>10</code>% of the data, the tuning model took over <code>35</code> minutes to run on a computer with 12 2.90GHz cores (hyper-threaded) with 1.7179869^{10} of RAM. Moreover, the model RMSE also only improved by <!--59.17-->. At least for this data, the additional time required to tune the model did not seem appropriate for the minimal increase in RMSE.</p>
<hr />
<center>
<em>Last updated: December 8th, 2020.</em>
</center>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
