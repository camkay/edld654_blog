<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Tensor Flo Ridas: A Journey in ML</title>

<script src="site_libs/header-attrs-2.5/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="custom.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">EDLD654</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="page1_data.html">
    <span class="fa fa-database"></span>
     
    The Data
  </a>
</li>
<li>
  <a href="page2_linear.html">
    <span class="fa fa-chart-line"></span>
     
    Linear Model
  </a>
</li>
<li>
  <a href="page3_rf.html">
    <span class="fa fa-tree"></span>
     
    Random Forest
  </a>
</li>
<li>
  <a href="page4_xgboost.html">
    <span class="fa fa-rocket"></span>
     
    Boosted Tree
  </a>
</li>
<li>
  <a href="page5_comparison.html">
    <span class="fa fa-balance-scale"></span>
     
    Model Comparisons
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/camkay/edld654_blog">
    <span class="fa fa-github"></span>
     
    GitHub
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Tensor Flo Ridas: A Journey in ML</h1>

</div>


<hr />
<div id="introduction-to-random-forest-models" class="section level1">
<h1>Introduction to Random Forest Models</h1>
<p>On this page, we provide an overview of how to fit and tune a random forest model. But, before we can get into fitting and tuning any models, it is important to describe what exactly a random forest model is. Before we can do that, however, we must also describe what decision trees and bootstrap aggregation (bagging) are.</p>
<p>An intuitive way to think of a decision tree is in terms of the parlor game <a href="https://en.wikipedia.org/wiki/Twenty_Questions">Twenty Questions</a> (see <a href="https://www.youtube.com/watch?v=pqrQJUY2_s8">Lecture 5 from Data Science Decal</a> for an extended discussion of this analogy). In <a href="https://en.wikipedia.org/wiki/Twenty_Questions">Twenty Questions</a>, one person (i.e., the answerer) thinks of a person, place, or thing (e.g., a computer), and the other other players (i.e., the askers) are allowed to ask 20 “yes” or “no” questions about the person, place, or thing (e.g., “Is it living?”). If the askers cannot guess what the person, place, or thing is after asking their 20 questions, the answerer wins. If they can guess what the person, place, or thing, the askers win and the answerer loses.</p>
<p>With decision trees, the computer essentially does the same thing as the askers in Twenty Questions. It uses yes or no questions about the predictors in a dataset to try to “guess” (predict) some categorical or continuous outcome variable of interest. For example, in predicting how much coffee a person drinks, the model might first split its prediction based on the person’s age (e.g., “Are they older than 18?”) and then, from there, split the prediction for those who are over 18 years of age by location (e.g., “Are they from Oregon or not?”). If the answer to those two questions is “yes”, then the computer may predict that a person drinks considerably more coffee than if the answer to those two questions is “no”. Moreover, by doing this splitting recursively, the computer is able to capture the interactions between these variables, such that the computer can provide a different prediction for a person who is over 18 <em>and</em> from Oregon than a person who is just over 18 or just from Oregon.</p>
<p>The primary problem with a decision tree is that it can easily be overfit. If the tree is just left to grow deeper and deeper it will eventually be able to predict the outcome in the present data well (i.e., it would have low bias) but not be generalizable to other datasets (i.e., it would have high variance).</p>
<p>One could stop growing the tree early or prune the tree back when it has grown too deep to address this overfitting, but another option is to use bagging. With bagging, multiple decision trees are created on bootstrap resamples of the training data and then the predictions are averaged together (if the outcome is continuous) or the most frequently predicted value across the trees is used (if the outcome is categorical). In doing so, a bagged model will have lower variance than a single decision tree alone. Moreover, since it has fuzzier decision boundaries (resulting from averaging predictions together), a bagged model will also generally have lower bias than a single decision tree.</p>
<p>This reduction in bias and variance is, however, only possible if the trees are sufficiently different from each other. If every tree was exactly the same, the averaged predictions would be exactly the same as a single decision tree. Random forests attempt to make bagged decision trees more dissimilar by only including a subset of the available predictors at each split. Returning to the example from above, it seems plausible that, even operating on a bootstrapped subsample of the data, whether a person is older than 18 or not will generally be more telling of how much coffee a person drinks than if they are from Oregon or not. By providing only a subset of the predictors at each split—such as in the case of a Random Forest model—some of the decision trees will not have age as a predictor at the root node and will, therefore, have to rely on different predictors for the initial split. By adding this additional random component, a Random Forest model is able to more effectively reduce its variance (and, potentially, bias) than a bagged model alone.</p>
</div>
<div id="fitting-an-untuned-random-forest-model" class="section level1">
<h1>Fitting an untuned random forest model</h1>
<div id="creating-the-model" class="section level2">
<h2>Creating the model</h2>
<p>To fit a random forest model, we start by creating a specification of the model by using the <code>random_forest()</code> function from <code>{parsnip}</code>. In this case, since we are predicting a continuous variable (i.e., <code>score</code>), we will want to set the mode to <code>"regression"</code> (using the <code>set_mode()</code> function).</p>
<p>Within the <code>set_engine()</code> function, we will want to set the engine to <code>"ranger"</code>. Although we could use <code>"randomForest"</code> as the engine, we are using <code>"ranger"</code> here because it is generally more computationally efficient. We will also want to set <code>num.threads</code> to the number of cores on our computer using <code>detectCores()</code> from the <code>{parallel}</code> package. This will allow <code>ranger</code> to parallelize the process of fitting the models, further speeding up computation times. We will also want to specify <code>importance = "permutation"</code> and <code>verbose = TRUE</code>. The former means that, when identifying the most important predictors among our models, the model will use permutation. In other words, predictors will be considered more important if shuffling their values results in greater prediction error. The latter means that R will tell us what step in the process we are at. Finally, we use <code>set_args</code> to set the number of trees to <code>500</code>. This means that our random forest model will create 500 decision trees. Although this is less than the number of trees recommended by Kuhn and Johnson (2013), we chose 500 to further reduce computation times and minimize potential memory issues (i.e., <a href="https://r.789695.n4.nabble.com/R-3-5-0-vector-memory-exhausted-error-on-readBin-td4750237.html">exhausting vector memory in R</a>).</p>
<pre class="r"><code>model_rf &lt;- rand_forest() %&gt;% 
  set_mode(&quot;regression&quot;) %&gt;% 
  set_engine(engine      = &quot;ranger&quot;,
             num.threads = parallel::detectCores(),
             importance  = &quot;permutation&quot;,
             verbose     = TRUE) %&gt;% 
  set_args(trees = 500)</code></pre>
</div>
<div id="creating-the-workflow" class="section level2">
<h2>Creating the workflow</h2>
<p>Once we have created the model, we can combine it with the recipe (see <a href="page1_data.html">The Data</a>) using the <code>workflow()</code> function from the <code>{workflows}</code> package. This allows us to only pass a single object (e.g., <code>workflow_rf</code>) to fit our model instead of having to pass multiple objects (e.g., <code>recipe_1</code> <em>and</em> <code>model_rf</code>).</p>
<pre class="r"><code># create workflow object
workflow_rf &lt;- workflow() %&gt;% 
  add_recipe(recipe_1) %&gt;% 
  add_model(model_rf)</code></pre>
</div>
<div id="fitting-the-model" class="section level2">
<h2>Fitting the model</h2>
<p>Now all that is left to do is to fit our model using <code>fit_resamples</code>. Here we used <code>metrics = yardstick::metric_set(rmse, rsq)</code> to request calculation of the average <em>Root Mean Square Error</em> (RMSE) and <span class="math inline">\(R^2\)</span> for the model. We also used <code>extract_model()</code> to extract the model that was created during each resampling. This will allow us to illustrate the most important predictors using the <code>vip()</code> function (see the section on <a href="#eip">Extracting Important Predictors</a> below). We also used the arguments <code>tic()</code> and <code>toc()</code> from the aptly named <code>{tictoc}</code> package to measure how long it takes the model to run.</p>
<pre class="r"><code># start timer
tictoc::tic()

# fit model
fit_rf &lt;- fit_resamples(
  object    = workflow_rf,
  resamples = data_train_cv,
  metrics   = yardstick::metric_set(rmse, rsq),
  control   = control_resamples(verbose   = TRUE,
                                save_pred = TRUE,
                                extract   = function(x) extract_model(x)))

# end timer
time1 &lt;- tictoc::toc()</code></pre>
<pre><code>## 154.771 sec elapsed</code></pre>
</div>
<div id="checking-model-metrics" class="section level2">
<h2>Checking model metrics</h2>
<p>Whew! It only took 154.771 seconds to run.</p>
<p>Now we can check the fit using the <code>collect_metrics()</code> function.</p>
<pre class="r"><code>collect_metrics(fit_rf) # 86.17</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[".metric"],"name":[1],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[2],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[4],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"rmse","2":"standard","3":"86.1653101","4":"10","5":"0.580063517"},{"1":"rsq","2":"standard","3":"0.4381685","4":"10","5":"0.006731574"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We can see that it had an RMSE of 86.17 and a <span class="math inline">\(R^2\)</span> of 0.44. In other words, our predictors explained an average of 43.82% of the variability in the total scores. Going forward, we will use only RMSE to evaluate model performance.</p>
</div>
<div id="eip" class="section level2">
<h2>Extracting important predictors</h2>
<p>We can also check the most important predictors in our trees using the <code>vip()</code> argument.</p>
<pre class="r"><code>pluck(fit_rf, &quot;.extracts&quot;, 1, &quot;.extracts&quot;, 1) %&gt;%
  vip(aesthetics = list(fill = &quot;cyan3&quot;), num_features = 20L) +
  labs(x = &quot;Predictor&quot;) + 
  theme_407()</code></pre>
<p><img src="page3_rf_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>As we can see, the student enrollment grade (<code>enrl_grade</code>) was one of the most important predictors when it came to predicting a student’s <code>score</code>. You might also notice that the graph of the important predictors has quite a long tail. If we had simply used bagging, the tail would have been a lot shorter. This is because, in Random Forest models, only a subset of the predictors is available when fitting each tree, resulting in some trees being fit without the strongest predictors that would generally serve as the root of the trees.</p>
</div>
</div>
<div id="fitting-a-tuned-random-forest-model" class="section level1">
<h1>Fitting a tuned random forest model</h1>
<p>With random forest models, there are three hyperparameters that can be tuned. The first is the number of <code>trees</code>, which we set to <code>500</code> in the previous model. With random forest models, people just have to ensure that there are enough trees to stabilize error rates. After the error rates are sufficiently stabilized, there are no other advantages of increasing the number of trees (and more trees will linearly increase computation times). As a result, people commonly only tune the minimum node size (<code>min_n</code>) and the number of predictors to be sampled at each split (<code>mtry</code>). The <code>min_n</code> hyperparameter controls how deep a tree will grow. A larger value will result in shallower trees, and a smaller value will result in deeper trees. The deeper a tree, the more likely it is to have high variance, whereas, the shallower a tree, the more likely it is to have high bias. The <code>mtry</code> hyperparameter, on the other hand, essentially controls how correlated a given set of trees will be. A higher value would be appropriate when a dataset has few relevant predictors (as it increases the chances that those predictors will be chosen), and a lower value would be appropriate when there are a large number of relevant predictors (as it allows predictors that are less strong but still relevant to form the base of the trees). To keep computation times down, we only provide an example of how to tune <code>min_n</code> here, but the process is quite similar for tuning <code>mtry</code>.</p>
<p>Below we add <code>min_n = tune()</code> to <code>set_args()</code> to tune the <code>min_n</code> hyperparameter.</p>
<div id="creating-the-model-1" class="section level2">
<h2>Creating the model</h2>
<pre class="r"><code>model_rf_tune &lt;- rand_forest() %&gt;% 
  set_mode(&quot;regression&quot;) %&gt;% 
  set_engine(engine      = &quot;ranger&quot;,
             num.threads = parallel::detectCores(),
             importance  = &quot;permutation&quot;,
             verbose     = TRUE) %&gt;% 
  set_args(trees = 500,
           min_n = tune())</code></pre>
</div>
<div id="updating-the-workflow-object" class="section level2">
<h2>Updating the workflow object</h2>
<p>Now that we have created this new model, we can update our workflow using the <code>update_model</code> function from <code>{workflows}</code>.</p>
<pre class="r"><code>workflow_rf_tune &lt;- workflow_rf %&gt;%
  update_model(model_rf_tune)</code></pre>
</div>
<div id="creating-the-tuning-grid" class="section level2">
<h2>Creating the tuning grid</h2>
<p>We also have to tell <code>{tidymodels}</code> what values to use for <code>min_n</code>. To do so, we can use the <code>grid_regular()</code> argument from <code>{dials}</code>. Below we request that 5 values (<code>levels</code>) be chosen for <code>min_n</code> between <code>1</code> and <code>10</code>.</p>
<pre class="r"><code># create grid
grid_rf &lt;- grid_regular(min_n(range = c(1, 10)), 
                        levels      = 5)</code></pre>
</div>
<div id="fitting-the-model-1" class="section level2">
<h2>Fitting the model</h2>
<p>Now, we can fit our model as we did above. However, we will want to use <code>tune_grid()</code> instead of <code>fit_resamples()</code> because we want to fit <code>500</code> decision trees using each of the <code>5</code> values of <code>min_n</code> that we specified above. We will also want to change <code>object = workflow_rf</code> to <code>object = workflow_rf_tune</code> to use our new workflow object. Finally, we will want to add <code>grid = grid_rf</code> so that <code>tune_grid()</code> knows what values of <code>min_n</code> to use.</p>
<pre class="r"><code># start timer
tictoc::tic()

# fit model
fit_rf_tune &lt;- tune_grid(
  object    = workflow_rf_tune,
  resamples = data_train_cv,
  grid      = grid_rf,
  metrics   = yardstick::metric_set(rmse, rsq),
  control   = control_resamples(verbose   = TRUE,
                                save_pred = TRUE,
                                extract   = function(x) extract_model(x)))

# end timer
time2 &lt;- tictoc::toc()</code></pre>
<pre><code>## 791.777 sec elapsed</code></pre>
</div>
<div id="checking-model-metrics-1" class="section level2">
<h2>Checking model metrics</h2>
<p>This time, it took 791.777 seconds to run. It is not surprising that it took longer, because we fit five times as many models as before.</p>
<p>Now we can use the <code>show_best()</code> function to examine our best fitting models.</p>
<pre class="r"><code>show_best(fit_rf_tune, metric = &quot;rmse&quot;, n = 5) # 85.77</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["min_n"],"name":[1],"type":["int"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"10","2":"rmse","3":"standard","4":"85.76636","5":"10","6":"0.5799668","7":"Model5"},{"1":"7","2":"rmse","3":"standard","4":"85.98384","5":"10","6":"0.5916483","7":"Model4"},{"1":"5","2":"rmse","3":"standard","4":"86.20442","5":"10","6":"0.5866762","7":"Model3"},{"1":"3","2":"rmse","3":"standard","4":"86.39005","5":"10","6":"0.5752793","7":"Model2"},{"1":"1","2":"rmse","3":"standard","4":"86.58000","5":"10","6":"0.5888000","7":"Model1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Here it appears that the best fitting model had a minimum node size of 10.00 and resulted in an RMSE of 85.77, a slight improvement over our previous RMSE of 86.17.</p>
</div>
<div id="plotting-the-tuned-values" class="section level2">
<h2>Plotting the tuned values</h2>
<p>To visualize the trend, we can use <code>autoplot()</code> to show us how average fit varied across different values of <code>min_n</code>.</p>
<pre class="r"><code>fit_rf_tune %&gt;%
  autoplot() +
  geom_line(color = &quot;cyan3&quot;) +
  geom_point(color = &quot;cyan3&quot;) +
  theme_407()</code></pre>
<p><img src="page3_rf_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Ah! It looks like the RMSE decreased all the way up to a <code>min_n</code> value of <code>10</code>. Is it possible that it would have reduced even more if we had provided a <code>min_n</code> that was greater than <code>10</code>?</p>
</div>
<div id="further-tuning" class="section level2">
<h2>Further tuning</h2>
<p>We can test this by testing a different grid. Let’s try testing 10 <code>min_n</code> values between <code>10</code> to <code>30</code></p>
<pre class="r"><code># create grid
grid_rf_2 &lt;- grid_regular(min_n(range = c(10, 30)), 
                          levels      = 10)</code></pre>
<p>To fit the model, we will simply substitute <code>grid_rf</code> for <code>grid_rf_2</code>.</p>
<pre class="r"><code># start timer
tictoc::tic()

# fit model
fit_rf_tune_2 &lt;- tune_grid(
  object    = workflow_rf_tune,
  resamples = data_train_cv,
  grid      = grid_rf_2,
  metrics   = yardstick::metric_set(rmse, rsq),
  control   = control_resamples(verbose   = TRUE,
                                save_pred = TRUE,
                                extract   = function(x) extract_model(x)))

# end timer
time3 &lt;- tictoc::toc()</code></pre>
<pre><code>## 1341.648 sec elapsed</code></pre>
<p>The new model took 1341.648 seconds to fit. Again, it makes sense that this would be longer, because we are now testing <code>10</code> hyperparameters instead of <code>5</code>.</p>
<p>We can then look at the metrics again…</p>
<pre class="r"><code>show_best(fit_rf_tune_2, metric = &quot;rmse&quot;, n = 10) # 85.3</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["min_n"],"name":[1],"type":["int"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"27","2":"rmse","3":"standard","4":"85.30140","5":"10","6":"0.6179977","7":"Model09"},{"1":"30","2":"rmse","3":"standard","4":"85.33087","5":"10","6":"0.6262129","7":"Model10"},{"1":"25","2":"rmse","3":"standard","4":"85.33128","5":"10","6":"0.6097008","7":"Model08"},{"1":"23","2":"rmse","3":"standard","4":"85.37347","5":"10","6":"0.6069483","7":"Model07"},{"1":"21","2":"rmse","3":"standard","4":"85.40271","5":"10","6":"0.6232605","7":"Model06"},{"1":"18","2":"rmse","3":"standard","4":"85.49974","5":"10","6":"0.6154056","7":"Model05"},{"1":"16","2":"rmse","3":"standard","4":"85.56783","5":"10","6":"0.6065154","7":"Model04"},{"1":"14","2":"rmse","3":"standard","4":"85.59051","5":"10","6":"0.5936204","7":"Model03"},{"1":"12","2":"rmse","3":"standard","4":"85.70580","5":"10","6":"0.5862275","7":"Model02"},{"1":"10","2":"rmse","3":"standard","4":"85.79425","5":"10","6":"0.5941898","7":"Model01"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>…and the plot showing average RMSE by <code>min_n</code>.</p>
<pre class="r"><code>fit_rf_tune_2 %&gt;%
  autoplot() +
  geom_line(color = &quot;cyan3&quot;) +
  geom_point(color = &quot;cyan3&quot;) +
  theme_407()</code></pre>
<p><img src="page3_rf_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>It looks like the best <code>min_n</code> (of the values we tested) was 27.00 which resulted in an average model RMSE of 85.30. This is marginally better than our previous best RMSE of 85.77.</p>
</div>
</div>
<div id="finalizing-the-model" class="section level1">
<h1>Finalizing the model</h1>
<p>Now that if we have finished training our model, we can test our model on the left out data. To do so, we will first want to use <code>finalize_workflow()</code> to update the workflow to use our most performant hyperparameters (i.e., <code>min_n =</code> 27.00).</p>
<pre class="r"><code>workflow_rf_final &lt;- finalize_workflow(
  workflow_rf_tune,
  select_best(fit_rf_tune_2, metric = &quot;rmse&quot;)
)</code></pre>
<p>Then we fit our model on our initial split data (<code>data_split</code>) using <code>last_fit()</code>.</p>
<pre class="r"><code># start timer
tictoc::tic()

# produce final fit
fit_rf_final &lt;- last_fit(workflow_rf_final, split = data_split)

# end timer
time4 &lt;- tictoc::toc()</code></pre>
<pre><code>## 15.035 sec elapsed</code></pre>
<p>Unsurprisingly, the model fit much faster than our previous model, coming in at 15.035 seconds.</p>
<pre class="r"><code>collect_metrics(fit_rf_final) # 87.25</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[".metric"],"name":[1],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimate"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"rmse","2":"standard","3":"87.2479913"},{"1":"rsq","2":"standard","3":"0.4365835"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The RMSE for the final fit was 87.25.</p>
</div>
<div id="final-thoughts" class="section level1">
<h1>Final thoughts</h1>
<p>Although the final model on the assessment set had a greater RMSE (i.e., 87.25) than the last model fit on the analysis set (i.e., 85.30), it was not drastically so. As such, it does not appear that our model was overfit to our data. It is, however, possible that using a value for <code>mtry</code> other than the default may have further decreased the variance.</p>
<p>With respect to tuning <code>min_n</code>, even when only using <code>500</code> <code>trees</code>, testing only <code>15</code> different values for the minimum node size (i.e., <code>min_n</code>), and using only <code>10</code>% of the data, the tuning models took over <code>35</code> minutes to run on a computer with 12 2.90GHz cores (hyper-threaded) with 16.00 of RAM. Moreover, the model RMSE only improved by 0.86. At least for this data, recipe, and model, the marginal improvement in the RMSE does not seem to outweigh the additional time required to tune <code>min_n</code>.</p>
<hr />
<center>
<em>Last updated: December 9th, 2020.</em>
</center>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
